# LLM-Powered Q&A System

##  Assessment Objective
This project is part of a pre-screening technical assessment designed to demonstrate proficiency in:

- Working with modern full-stack technologies
- Implementing AI/LLM integrations
- Creating user-friendly interfaces
- Writing clean, maintainable code
- Handling API integrations effectively
- Showcasing strong decision-making skills

---

## Technical Stack
- **Backend**: Python (FastAPI)
- **Frontend**: Next.js (latest version)
- **Styling**: TailwindCSS
- **LLM Integration**: ChatGPT

---

##  Project Overview

**LLM-Powered Q&A System** is a smart, real-time question-and-answer platform built using FastAPI and Next.js.  
It allows users to ask questions and receive detailed, structured, and well-formatted answers powered by a Large Language Model (LLM).

Example use case:  
> **User Input**: "What documents do I need to travel from Kenya to Ireland?"  
> **System Response**:
> - Required visa documentation
> - Passport requirements
> - Additional necessary documents
> - Relevant travel advisories

---

## Features
- Interactive chat interface
- Real-time LLM responses
- Well-formatted and structured outputs
- Mobile-responsive UI
- Error handling and graceful fallbacks
- Clean, maintainable codebase

---

##  How to Run Locally

### Backend (FastAPI)
```bash
# Navigate to the backend directory
cd backend

# Install dependencies
pip install -r requirements.txt

# Start FastAPI server
uvicorn main:app --reload
```

### Frontend (Next.js)
```bash
# Navigate to the frontend directory
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

---

## üîó Live Demo
Coming soon!

---

## ‚úçÔ∏è Final Note
I HAVE CLEARLY UNDERSTOOD THE KEY POINTERS FOR THE TECHNICAL ASSESSMENT.
